{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"226ad19d6a33498db2c20704e20fc3a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_682095ea913244f595cb6e21f9c8a2a1","IPY_MODEL_93e5eca540284df48009780d47a0b3ca","IPY_MODEL_e8066f22838040b7b6b863c5008f66ff"],"layout":"IPY_MODEL_c5d1b6fdee22412f9dbd073d819ac282"}},"682095ea913244f595cb6e21f9c8a2a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e85de600699147ac93c6b34aa0ab5fc7","placeholder":"​","style":"IPY_MODEL_2730ac0214e6496f91bf78e4ead8b362","value":"Loading checkpoint shards: 100%"}},"93e5eca540284df48009780d47a0b3ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27e051b8bcfa4f3d98bdd8534bfb8bf4","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c8b7a9488704b8d945b90a1dd433144","value":8}},"e8066f22838040b7b6b863c5008f66ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd7a1f8cf6af43a597d684fd31c1fdb8","placeholder":"​","style":"IPY_MODEL_4e17fec0ae2f478eb253b3fb5e0b1f86","value":" 8/8 [01:02&lt;00:00,  6.82s/it]"}},"c5d1b6fdee22412f9dbd073d819ac282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e85de600699147ac93c6b34aa0ab5fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2730ac0214e6496f91bf78e4ead8b362":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27e051b8bcfa4f3d98bdd8534bfb8bf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c8b7a9488704b8d945b90a1dd433144":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd7a1f8cf6af43a597d684fd31c1fdb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e17fec0ae2f478eb253b3fb5e0b1f86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:55:22.900786Z","iopub.execute_input":"2025-06-08T15:55:22.901107Z","iopub.status.idle":"2025-06-08T15:55:23.024053Z","shell.execute_reply.started":"2025-06-08T15:55:22.901081Z","shell.execute_reply":"2025-06-08T15:55:23.022841Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone --branch main https://github.com/giankev/Ancient-to-Modern-Italian-Automatic-Translation.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:55:25.593396Z","iopub.execute_input":"2025-06-08T15:55:25.594084Z","iopub.status.idle":"2025-06-08T15:55:26.118690Z","shell.execute_reply.started":"2025-06-08T15:55:25.594053Z","shell.execute_reply":"2025-06-08T15:55:26.118028Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Ancient-to-Modern-Italian-Automatic-Translation'...\nremote: Enumerating objects: 132, done.\u001b[K\nremote: Counting objects: 100% (132/132), done.\u001b[K\nremote: Compressing objects: 100% (112/112), done.\u001b[K\nremote: Total 132 (delta 69), reused 50 (delta 16), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (132/132), 390.65 KiB | 5.66 MiB/s, done.\nResolving deltas: 100% (69/69), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"CUDA (GPU) not available, using CPU.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:55:27.983060Z","iopub.execute_input":"2025-06-08T15:55:27.983345Z","iopub.status.idle":"2025-06-08T15:55:29.687662Z","shell.execute_reply.started":"2025-06-08T15:55:27.983320Z","shell.execute_reply":"2025-06-08T15:55:29.686952Z"}},"outputs":[{"name":"stdout","text":"Using GPU: Tesla T4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(torch.cuda.device_count())\nprint(torch.cuda.get_device_name(0)) \nprint(torch.cuda.get_device_name(1)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:55:32.506227Z","iopub.execute_input":"2025-06-08T15:55:32.506664Z","iopub.status.idle":"2025-06-08T15:55:32.511609Z","shell.execute_reply.started":"2025-06-08T15:55:32.506642Z","shell.execute_reply":"2025-06-08T15:55:32.510888Z"}},"outputs":[{"name":"stdout","text":"2\nTesla T4\nTesla T4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ngemma2b_it_cl_translation = pd.read_csv(\"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/Gemma2b-it-translation/CulturalI-hw2_transl-Gemma2b-it_context_learning.csv\")\ndataset_gold = pd.read_csv(\"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/dataset/dataset_gold.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:55:50.999296Z","iopub.execute_input":"2025-06-08T15:55:50.999894Z","iopub.status.idle":"2025-06-08T15:55:51.358424Z","shell.execute_reply.started":"2025-06-08T15:55:50.999872Z","shell.execute_reply":"2025-06-08T15:55:51.357900Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"gemma2b_it_cl_translation.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_gold.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_concat = pd.concat([gemma2b_it_cl_translation, dataset_gold], axis=1)  # axis=0 indica concatenazione per righe (verticale)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:56:05.890196Z","iopub.execute_input":"2025-06-08T15:56:05.890509Z","iopub.status.idle":"2025-06-08T15:56:05.895798Z","shell.execute_reply.started":"2025-06-08T15:56:05.890488Z","shell.execute_reply":"2025-06-08T15:56:05.894930Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df_concat.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_concat.rename(columns={'translation': 'response'}, inplace=True)\ndf_concat.rename(columns={'Translation': 'reference_answer'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:56:09.150787Z","iopub.execute_input":"2025-06-08T15:56:09.151380Z","iopub.status.idle":"2025-06-08T15:56:09.156019Z","shell.execute_reply.started":"2025-06-08T15:56:09.151357Z","shell.execute_reply":"2025-06-08T15:56:09.155206Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_concat = df_concat[[\"response\",\"reference_answer\"]]\ndf_concat.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:56:11.888641Z","iopub.execute_input":"2025-06-08T15:56:11.889344Z","iopub.status.idle":"2025-06-08T15:56:11.899253Z","shell.execute_reply.started":"2025-06-08T15:56:11.889318Z","shell.execute_reply":"2025-06-08T15:56:11.898685Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                            response  \\\n0  \"Quella guerra ben fatta, l'opera perché etc. ...   \n1  \"crudele, e di tutte le colpe si prende vendet...   \n2  \"Non ha altra forza d'animo che l'onore di Pon...   \n3  \"Se questo piace a tutti e se il tempo ha biso...   \n4  \"L'arte di questa disciplina sembra essere que...   \n\n                                    reference_answer  \n0  Quella guerra è stata combattuta per una giust...  \n1  È crudele e punisce ogni colpa come vuole la l...  \n2  Ponzio Aufidiano non aveva coraggio d’animo, e...  \n3  Se per tutti va bene avere Pompeo come cavalie...  \n4  Il compito di quest’arte sembra essere parlare...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>response</th>\n      <th>reference_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"Quella guerra ben fatta, l'opera perché etc. ...</td>\n      <td>Quella guerra è stata combattuta per una giust...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"crudele, e di tutte le colpe si prende vendet...</td>\n      <td>È crudele e punisce ogni colpa come vuole la l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Non ha altra forza d'animo che l'onore di Pon...</td>\n      <td>Ponzio Aufidiano non aveva coraggio d’animo, e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Se questo piace a tutti e se il tempo ha biso...</td>\n      <td>Se per tutti va bene avere Pompeo come cavalie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"L'arte di questa disciplina sembra essere que...</td>\n      <td>Il compito di quest’arte sembra essere parlare...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"ABS_SYSTEM_PROMPT = \"\"\"You are a fair judge assistant tasked with providing clear,\n                     objective feedback based on specific criteria, ensuring each assessment\n                     reflects the absolute standards set for performance.\"\"\"\n\nABSOLUTE_PROMPT = \"\"\"###Task Description:\nAn instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n4. Please do not generate any other opening, closing, and explanations.\n\n###The instruction to evaluate:\n{instruction}\n\n###Response to evaluate:\n{response}\n\n###Reference Answer:\n{reference_answer}\n\n###Score Rubrics:\n{rubric}\n\n###Feedback: \"\"\"\n\ndef build_prometheus_prompt(response_given: str, reference_answer: str):\n    instruction = \"Evaluate the translation from Old Italian to Modern Italian.\"\n    response = response_given\n    reference = reference_answer\n    rubric = \"\"\"Semantic fidelity and grammatical correctness:\n                Score 1: Completely unacceptable translation: irrelevant, incomprehensible, or nonsensical.\n                Score 2: Severe semantic errors, substantial omissions or additions. Defective syntax.\n                Score 3: Mediocre translation with minor semantic mistakes or typos.\n                Score 4: Good translation, faithful and understandable with slight stylistic imperfections.\n                Score 5: Perfect translation: accurate, fluent, coherent, and semantically correct.\"\"\"\n\n    return ABS_SYSTEM_PROMPT + \"\\n\\n\" + ABSOLUTE_PROMPT.format(\n        instruction=instruction,\n        response=response_given,\n        reference_answer=reference_answer,\n        rubric=rubric\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:56:14.819750Z","iopub.execute_input":"2025-06-08T15:56:14.820352Z","iopub.status.idle":"2025-06-08T15:56:14.825377Z","shell.execute_reply.started":"2025-06-08T15:56:14.820332Z","shell.execute_reply":"2025-06-08T15:56:14.824753Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"prometheus-eval/prometheus-7b-v2.0\", device_map = \"auto\")\ntokenizer = AutoTokenizer.from_pretrained(\"prometheus-eval/prometheus-7b-v2.0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T15:56:18.034827Z","iopub.execute_input":"2025-06-08T15:56:18.035424Z","iopub.status.idle":"2025-06-08T15:56:45.929835Z","shell.execute_reply.started":"2025-06-08T15:56:18.035401Z","shell.execute_reply":"2025-06-08T15:56:45.929049Z"}},"outputs":[{"name":"stderr","text":"2025-06-08 15:56:21.465973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749398181.489253     259 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749398181.496211     259 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5d76cc7b3a417a9dd86eb02b6a1cb2"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T17:27:54.787892Z","iopub.execute_input":"2025-06-08T17:27:54.788474Z","iopub.status.idle":"2025-06-08T17:27:54.792166Z","shell.execute_reply.started":"2025-06-08T17:27:54.788453Z","shell.execute_reply":"2025-06-08T17:27:54.791362Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def evaluations(df, output_csv_path):\n    \n    results = []\n    for index, item in tqdm(df.iterrows(), total=df.shape[0], desc=\"Evaluations\", unit=\"phrase\"):\n        response = item[\"response\"]\n        reference_answer = item[\"reference_answer\"]\n        prompt_text = build_prometheus_prompt(response, reference_answer)\n        \n        messages = [\n            {\"role\": \"user\", \"content\": prompt_text},\n        ]\n        \n        encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n        \n        \n        if tokenizer.pad_token_id is None:\n           tokenizer.pad_token_id = tokenizer.eos_token_id\n\n        #encodeds = {k: v.to(model.device) for k, v in encodeds.items()}\n\n        with torch.no_grad():\n            generated_ids = model.generate(\n                            encodeds,\n                            max_new_tokens=1000,\n                            do_sample=False,   \n                            temperature=0.0,    \n                            pad_token_id=tokenizer.pad_token_id, \n                            eos_token_id=tokenizer.eos_token_id     \n                        )\n            \n        decoded = tokenizer.batch_decode(generated_ids)\n    \n        score = \"\"\n        if \"[RESULT]\" in decoded[0]:\n          score = decoded[0].split(\"[RESULT]\")[-1].strip().replace(\"</s>\", \"\").strip() \n    \n        if (index + 1) % 10 == 0:\n                print(f\"\\nProcessed {index + 1} phrase.\")\n    \n        results.append({\n                'response': response,\n                'reference_answer': reference_answer,\n                'score': score\n            })\n        \n    df_output = pd.DataFrame(results)\n    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n    df_output.to_csv(output_csv_path, index=False, encoding='utf-8')\n        \n    print(f\"\\nTranslation complete. Results saved in: {output_csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T17:27:50.435537Z","iopub.execute_input":"2025-06-08T17:27:50.435829Z","iopub.status.idle":"2025-06-08T17:27:50.443220Z","shell.execute_reply.started":"2025-06-08T17:27:50.435811Z","shell.execute_reply":"2025-06-08T17:27:50.442584Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"output_csv_path = \"/kaggle/working/Gemma2b-it-evaluations_prometheus.csv\"\nevaluations(df_concat, output_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T17:27:57.740231Z","iopub.execute_input":"2025-06-08T17:27:57.740847Z","iopub.status.idle":"2025-06-08T18:13:29.714909Z","shell.execute_reply.started":"2025-06-08T17:27:57.740824Z","shell.execute_reply":"2025-06-08T18:13:29.714083Z"}},"outputs":[{"name":"stderr","text":"Evaluations:  10%|█         | 10/97 [04:18<37:20, 25.75s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 10 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  21%|██        | 20/97 [08:44<34:57, 27.24s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 20 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  31%|███       | 30/97 [13:07<30:41, 27.49s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 30 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  41%|████      | 40/97 [19:34<43:41, 45.99s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 40 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  52%|█████▏    | 50/97 [24:07<21:15, 27.14s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 50 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  62%|██████▏   | 60/97 [28:38<16:15, 26.37s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 60 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  72%|███████▏  | 70/97 [33:22<12:47, 28.43s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 70 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  82%|████████▏ | 80/97 [37:55<07:31, 26.58s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 80 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations:  93%|█████████▎| 90/97 [42:15<02:39, 22.85s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nProcessed 90 phrase.\n","output_type":"stream"},{"name":"stderr","text":"Evaluations: 100%|██████████| 97/97 [45:31<00:00, 28.16s/phrase]","output_type":"stream"},{"name":"stdout","text":"\nTranslation complete. Results saved in: /kaggle/working/Gemma2b-it-evaluations_prometheus.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import pandas as pd\n\n# Carica il CSV\ndf = pd.read_csv(\"/kaggle/working/Gemma2b-it-evaluations_prometheus.csv\")\n\n# Salva in formato JSON Lines\ndf.to_json(\"/kaggle/working/Gemma2b-it-evaluations_prometheus.jsonl\", orient=\"records\", lines=True, force_ascii=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T18:23:32.248777Z","iopub.execute_input":"2025-06-08T18:23:32.249351Z","iopub.status.idle":"2025-06-08T18:23:32.257252Z","shell.execute_reply.started":"2025-06-08T18:23:32.249329Z","shell.execute_reply":"2025-06-08T18:23:32.256533Z"}},"outputs":[],"execution_count":49}]}