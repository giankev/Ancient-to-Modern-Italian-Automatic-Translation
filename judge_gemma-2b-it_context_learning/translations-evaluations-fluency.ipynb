{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:15:53.798800Z",
     "iopub.status.busy": "2025-06-06T17:15:53.798516Z",
     "iopub.status.idle": "2025-06-06T17:15:53.920428Z",
     "shell.execute_reply": "2025-06-06T17:15:53.919452Z",
     "shell.execute_reply.started": "2025-06-06T17:15:53.798776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:16:34.932260Z",
     "iopub.status.busy": "2025-06-06T17:16:34.931498Z",
     "iopub.status.idle": "2025-06-06T17:16:39.998671Z",
     "shell.execute_reply": "2025-06-06T17:16:39.997976Z",
     "shell.execute_reply.started": "2025-06-06T17:16:34.932220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.0/200.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:16:46.915208Z",
     "iopub.status.busy": "2025-06-06T17:16:46.914922Z",
     "iopub.status.idle": "2025-06-06T17:16:47.626329Z",
     "shell.execute_reply": "2025-06-06T17:16:47.625098Z",
     "shell.execute_reply.started": "2025-06-06T17:16:46.915181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Ancient-to-Modern-Italian-Automatic-Translation'...\n",
      "remote: Enumerating objects: 60, done.\u001b[K\n",
      "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
      "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
      "remote: Total 60 (delta 29), reused 36 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (60/60), 57.08 KiB | 2.28 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone --branch main https://github.com/giankev/Ancient-to-Modern-Italian-Automatic-Translation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:17:03.432777Z",
     "iopub.status.busy": "2025-06-06T17:17:03.432483Z",
     "iopub.status.idle": "2025-06-06T17:17:03.558372Z",
     "shell.execute_reply": "2025-06-06T17:17:03.557547Z",
     "shell.execute_reply.started": "2025-06-06T17:17:03.432749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY Loaded\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import huggingface_hub\n",
    "import os\n",
    "\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    API_KEY = user_secrets.get_secret(\"api_google_ai\")\n",
    "    print(\"API KEY Loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during programmatic login: {e}\")\n",
    "    print(\"Please ensure your HF_TOKEN secret is correctly set in Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:17:05.409353Z",
     "iopub.status.busy": "2025-06-06T17:17:05.409021Z",
     "iopub.status.idle": "2025-06-06T17:17:05.413533Z",
     "shell.execute_reply": "2025-06-06T17:17:05.412780Z",
     "shell.execute_reply.started": "2025-06-06T17:17:05.409327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:26:24.194689Z",
     "iopub.status.busy": "2025-06-06T17:26:24.194123Z",
     "iopub.status.idle": "2025-06-06T17:26:24.201253Z",
     "shell.execute_reply": "2025-06-06T17:26:24.200526Z",
     "shell.execute_reply.started": "2025-06-06T17:26:24.194667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_translation = \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/Gemma2b-it-translation/CulturalIA-hw2_transl-Gemma2b-it_context_learning.csv\"\n",
    "df = pd.read_csv(csv_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:26:27.033024Z",
     "iopub.status.busy": "2025-06-06T17:26:27.032790Z",
     "iopub.status.idle": "2025-06-06T17:26:27.054464Z",
     "shell.execute_reply": "2025-06-06T17:26:27.053895Z",
     "shell.execute_reply.started": "2025-06-06T17:26:27.033009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_text</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quella guerra ben fatta l' opera perché etc. E...</td>\n",
       "      <td>\"Quella guerra ben fatta, l'opera perché etc. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crudele, e di tutte le colpe pigli vendetta, c...</td>\n",
       "      <td>\"crudele, e di tutte le colpe si prende vendet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non d' altra forza d' animo fue ornato Ponzio ...</td>\n",
       "      <td>\"Non ha altra forza d'animo che l'onore di Pon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se questo piace a tutti e se 'l tempo hae biso...</td>\n",
       "      <td>\"Se questo piace a tutti e se il tempo ha biso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Officio di questa arte pare che sia dicere app...</td>\n",
       "      <td>\"L'arte di questa disciplina sembra essere que...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            old_text  \\\n",
       "0  quella guerra ben fatta l' opera perché etc. E...   \n",
       "1  crudele, e di tutte le colpe pigli vendetta, c...   \n",
       "2  Non d' altra forza d' animo fue ornato Ponzio ...   \n",
       "3  Se questo piace a tutti e se 'l tempo hae biso...   \n",
       "4  Officio di questa arte pare che sia dicere app...   \n",
       "\n",
       "                                         translation  \n",
       "0  \"Quella guerra ben fatta, l'opera perché etc. ...  \n",
       "1  \"crudele, e di tutte le colpe si prende vendet...  \n",
       "2  \"Non ha altra forza d'animo che l'onore di Pon...  \n",
       "3  \"Se questo piace a tutti e se il tempo ha biso...  \n",
       "4  \"L'arte di questa disciplina sembra essere que...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:19:16.457731Z",
     "iopub.status.busy": "2025-06-06T17:19:16.456907Z",
     "iopub.status.idle": "2025-06-06T17:19:18.218184Z",
     "shell.execute_reply": "2025-06-06T17:19:18.217688Z",
     "shell.execute_reply.started": "2025-06-06T17:19:16.457699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T16:01:20.305155Z",
     "iopub.status.busy": "2025-06-06T16:01:20.304473Z",
     "iopub.status.idle": "2025-06-06T16:01:20.309481Z",
     "shell.execute_reply": "2025-06-06T16:01:20.308693Z",
     "shell.execute_reply.started": "2025-06-06T16:01:20.305128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prompt_evaluation(original: str, translated: str):\n",
    "    prompt =  f\"\"\"Valuta la seguente traduzione dall'italiano antico all'italiano moderno.\n",
    "                Concentrati sulla fedeltà semantica e la correttezza grammaticale.\n",
    "                Fornisci un punteggio da 1 a 5 basandoti sulla seguente rubrica:\n",
    "                1. Traduzione completamente inaccettabile: la traduzione non ha pertinenza con il significato originale, la frase generata è incomprensibile (gibberish) o senza senso.\n",
    "                2. Errori semantici gravi, omissioni o aggiunte sostanziali rispetto alla frase originale. Gli errori sono di natura semantica e sintattica. È qualcosa che un umano non scriverebbe mai.\n",
    "                3. Traduzione parzialmente errata: la traduzione è mediocre, contiene errori, ma sono per lo più errori minori, come refusi o piccoli errori semantici.\n",
    "                4. Buona traduzione: la traduzione è per lo più corretta, sostanzialmente fedele al testo originale, ma lo stile potrebbe non corrispondere perfettamente alla frase originale; è comunque fluente, comprensibile e semanticamente accettabile.\n",
    "                5. Traduzione perfetta: la traduzione è accurata, fluente, completa e coerente. Ha mantenuto il significato originale il più possibile.\n",
    "                fornisci solo il numero del punteggio (da 1 a 5).\n",
    "                frase originale: \"{original}\"\n",
    "                frase tradotta: \"{translated}\"\n",
    "                \n",
    "                \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:25:45.527164Z",
     "iopub.status.busy": "2025-06-06T17:25:45.526890Z",
     "iopub.status.idle": "2025-06-06T17:25:45.531437Z",
     "shell.execute_reply": "2025-06-06T17:25:45.530863Z",
     "shell.execute_reply.started": "2025-06-06T17:25:45.527142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prompt_evaluation_fluency(original: str, translated: str) -> str:\n",
    "    prompt = f\"\"\"Valuta ESCLUSIVAMENTE la FLUENZA e la NATURALEZZA della seguente traduzione in italiano moderno.\n",
    "                Ignora per ora la sua precisione semantica rispetto al testo originale arcaico.\n",
    "                Fornisci un punteggio da 1 a 3 basandoti sulla seguente rubrica:\n",
    "                \n",
    "                1. Poco Fluida/Innaturale: La frase moderna è sgrammaticata, difficile da capire, o suona artificiale e non come la scriverebbe un madrelingua.\n",
    "                2. Abbastanza Fluida: La frase moderna è grammaticalmente comprensibile ma presenta parole usate in modo errato che ne riducono la naturalezza.\n",
    "                3. Perfettamente Fluida e Naturale: La frase moderna scorre bene, usa un lessico e una sintassi del tutto appropriati per l'italiano moderno e suona naturale.\n",
    "                \n",
    "                Fornisci solo il numero del punteggio (da 1 a 3).\n",
    "                \n",
    "                frase originale (Italiano Antico): \"{original}\"\n",
    "                traduzione proposta (Italiano Moderno da Valutare): \"{translated}\"\n",
    "                \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:26:52.902318Z",
     "iopub.status.busy": "2025-06-06T17:26:52.901498Z",
     "iopub.status.idle": "2025-06-06T17:30:35.999879Z",
     "shell.execute_reply": "2025-06-06T17:30:35.999330Z",
     "shell.execute_reply.started": "2025-06-06T17:26:52.902269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    original = row[\"old_text\"]\n",
    "    translation = row[\"translation\"]\n",
    "    prompt = prompt_evaluation_fluency(original, translation)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "             model=\"gemini-2.0-flash-lite\",\n",
    "             contents=prompt\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"sentence\": original,\n",
    "        \"translation\": translation,\n",
    "        \"score\": response.text\n",
    "    })\n",
    "\n",
    "    sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:30:54.580148Z",
     "iopub.status.busy": "2025-06-06T17:30:54.579501Z",
     "iopub.status.idle": "2025-06-06T17:30:54.592023Z",
     "shell.execute_reply": "2025-06-06T17:30:54.591311Z",
     "shell.execute_reply.started": "2025-06-06T17:30:54.580127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"/kaggle/working/evaluation_Gemma2b-it_fluency.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:30:56.779852Z",
     "iopub.status.busy": "2025-06-06T17:30:56.779127Z",
     "iopub.status.idle": "2025-06-06T17:30:56.787225Z",
     "shell.execute_reply": "2025-06-06T17:30:56.786655Z",
     "shell.execute_reply.started": "2025-06-06T17:30:56.779829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/kaggle/working/evaluation_Gemma2b-it_fluency.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in results:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7590803,
     "sourceId": 12060190,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
