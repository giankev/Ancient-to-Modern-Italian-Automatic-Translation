{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:35:19.257219Z",
     "iopub.status.busy": "2025-06-04T14:35:19.256992Z",
     "iopub.status.idle": "2025-06-04T14:35:24.152483Z",
     "shell.execute_reply": "2025-06-04T14:35:24.151829Z",
     "shell.execute_reply.started": "2025-06-04T14:35:19.257198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --branch main https://github.com/giankev/Ancient-to-Modern-Italian-Automatic-Translation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:03:18.470805Z",
     "iopub.status.busy": "2025-06-04T15:03:18.470055Z",
     "iopub.status.idle": "2025-06-04T15:03:18.547629Z",
     "shell.execute_reply": "2025-06-04T15:03:18.546932Z",
     "shell.execute_reply.started": "2025-06-04T15:03:18.470775Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY Loaded\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import huggingface_hub\n",
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    API_KEY = user_secrets.get_secret(\"api_google_ai\")\n",
    "    print(\"API KEY Loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during programmatic login: {e}\")\n",
    "    print(\"Please ensure your HF_TOKEN secret is correctly set in Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:46:28.429582Z",
     "iopub.status.busy": "2025-06-04T15:46:28.429321Z",
     "iopub.status.idle": "2025-06-04T15:46:28.432909Z",
     "shell.execute_reply": "2025-06-04T15:46:28.432346Z",
     "shell.execute_reply.started": "2025-06-04T15:46:28.429566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:10:59.425232Z",
     "iopub.status.busy": "2025-06-04T15:10:59.424957Z",
     "iopub.status.idle": "2025-06-04T15:10:59.733151Z",
     "shell.execute_reply": "2025-06-04T15:10:59.732664Z",
     "shell.execute_reply.started": "2025-06-04T15:10:59.425214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_translation = \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/Gemma2b-it-translation/CulturalIA-hw2_transl-Gemma2b-it_context_learning.csv\"\n",
    "df = pd.read_csv(csv_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:11:08.567505Z",
     "iopub.status.busy": "2025-06-04T15:11:08.567245Z",
     "iopub.status.idle": "2025-06-04T15:11:08.667155Z",
     "shell.execute_reply": "2025-06-04T15:11:08.666500Z",
     "shell.execute_reply.started": "2025-06-04T15:11:08.567486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_text</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quella guerra ben fatta l' opera perché etc. E...</td>\n",
       "      <td>\"Quella guerra ben fatta, l'opera perché etc. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crudele, e di tutte le colpe pigli vendetta, c...</td>\n",
       "      <td>\"crudele, e di tutte le colpe si prende vendet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non d' altra forza d' animo fue ornato Ponzio ...</td>\n",
       "      <td>\"Non ha altra forza d'animo che l'onore di Pon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se questo piace a tutti e se 'l tempo hae biso...</td>\n",
       "      <td>\"Se questo piace a tutti e se il tempo ha biso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Officio di questa arte pare che sia dicere app...</td>\n",
       "      <td>\"L'arte di questa disciplina sembra essere que...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            old_text  \\\n",
       "0  quella guerra ben fatta l' opera perché etc. E...   \n",
       "1  crudele, e di tutte le colpe pigli vendetta, c...   \n",
       "2  Non d' altra forza d' animo fue ornato Ponzio ...   \n",
       "3  Se questo piace a tutti e se 'l tempo hae biso...   \n",
       "4  Officio di questa arte pare che sia dicere app...   \n",
       "\n",
       "                                         translation  \n",
       "0  \"Quella guerra ben fatta, l'opera perché etc. ...  \n",
       "1  \"crudele, e di tutte le colpe si prende vendet...  \n",
       "2  \"Non ha altra forza d'animo che l'onore di Pon...  \n",
       "3  \"Se questo piace a tutti e se il tempo ha biso...  \n",
       "4  \"L'arte di questa disciplina sembra essere que...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:35:10.820491Z",
     "iopub.status.busy": "2025-06-04T15:35:10.820239Z",
     "iopub.status.idle": "2025-06-04T15:35:10.825232Z",
     "shell.execute_reply": "2025-06-04T15:35:10.824481Z",
     "shell.execute_reply.started": "2025-06-04T15:35:10.820473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prompt_evaluation(original: str, translated: str):\n",
    "    prompt =  f\"\"\"Valuta la seguente traduzione dall'italiano antico all'italiano moderno.\n",
    "                Concentrati sulla fedeltà semantica e la correttezza grammaticale.\n",
    "                Fornisci un punteggio da 1 a 5 basandoti sulla seguente rubrica:\n",
    "                1. Traduzione completamente inaccettabile: la traduzione non ha pertinenza con il significato originale, la frase generata è incomprensibile (gibberish) o senza senso.\n",
    "                2. Errori semantici gravi, omissioni o aggiunte sostanziali rispetto alla frase originale. Gli errori sono di natura semantica e sintattica. È qualcosa che un umano non scriverebbe mai.\n",
    "                3. Traduzione parzialmente errata: la traduzione è mediocre, contiene errori, ma sono per lo più errori minori, come refusi o piccoli errori semantici.\n",
    "                4. Buona traduzione: la traduzione è per lo più corretta, sostanzialmente fedele al testo originale, ma lo stile potrebbe non corrispondere perfettamente alla frase originale; è comunque fluente, comprensibile e semanticamente accettabile.\n",
    "                5. Traduzione perfetta: la traduzione è accurata, fluente, completa e coerente. Ha mantenuto il significato originale il più possibile.\n",
    "                fornisci solo il numero del punteggio (da 1 a 5).\n",
    "                frase originale: \"{original}\"\n",
    "                frase tradotta: \"{translated}\"\n",
    "                \n",
    "                \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:58:23.297099Z",
     "iopub.status.busy": "2025-06-04T15:58:23.296844Z",
     "iopub.status.idle": "2025-06-04T16:02:09.868432Z",
     "shell.execute_reply": "2025-06-04T16:02:09.867687Z",
     "shell.execute_reply.started": "2025-06-04T15:58:23.297080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    original = row[\"old_text\"]\n",
    "    translation = row[\"translation\"]\n",
    "    prompt = prompt_evaluation(original, translation)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "             model=\"gemini-2.0-flash-lite\",\n",
    "             contents=prompt\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"sentence\": original,\n",
    "        \"translation\": translation,\n",
    "        \"score\": response.text\n",
    "    })\n",
    "\n",
    "    sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T16:07:09.293940Z",
     "iopub.status.busy": "2025-06-04T16:07:09.293702Z",
     "iopub.status.idle": "2025-06-04T16:07:09.300047Z",
     "shell.execute_reply": "2025-06-04T16:07:09.299481Z",
     "shell.execute_reply.started": "2025-06-04T16:07:09.293925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"/kaggle/working/evaluation_gemma2b-it_context_learning.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T16:08:16.045463Z",
     "iopub.status.busy": "2025-06-04T16:08:16.045206Z",
     "iopub.status.idle": "2025-06-04T16:08:16.051778Z",
     "shell.execute_reply": "2025-06-04T16:08:16.051210Z",
     "shell.execute_reply.started": "2025-06-04T16:08:16.045443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/kaggle/working/evaluation_gemma2b-it_context_learning.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in results:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7590803,
     "sourceId": 12060190,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
