{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"rm -rf /kaggle/working/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone --branch main https://github.com/giankev/Ancient-to-Modern-Italian-Automatic-Translation.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom scipy.stats import pearsonr, spearmanr\n\ndef metric_score(path_human_score, path_LLM_judge_score):\n\n    human_score = pd.read_csv(path_human_score)\n    LLM_judge_score = pd.read_csv(path_LLM_judge_score)\n    \n    LLM_judge_score = LLM_judge_score[\"score\"]\n    human_score = human_score[\"human score\"]\n    \n    kappa = cohen_kappa_score(human_score, LLM_judge_score)\n    spearman, _ = spearmanr(human_score, LLM_judge_score)\n\n    return kappa, spearman","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"experiments = [\n    (\"gemma2b_it_context_learning\",\n     \"gemini-2.0-flash-lite\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_gemma2b-it_context_learning.csv\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/judge_gemma-2b-it_context_learning/CulturalIA-hw2_transl-judge.csv\"\n    ),\n\n    (\"gemma2b_it_context_learning\",\n     \"prometheus\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_gemma2b-it_context_learning.csv\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/prometheus/Gemma2b-it-evaluations_prometheus.csv\"\n    ),\n\n    (\"opusMT\",\n     \"gemini-2.0-flash-lite\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_opusMT.csv\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/judge_opusMT/CulturalIA-hw2_transl-judge.csv\"   \n    ),\n\n    (\"opusMT\",\n     \"prometheus\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_opusMT.csv\",\n     \"/kaggle/working/Ancient-to-Modern-Italian-Automatic-Translation/prometheus/OpusMT-it-evaluations_prometheus.csv\"   \n    ) \n]\n\nresults = []\n\nfor model_name,llm_judge, path_human, path_llm in experiments:\n    kappa, spearman = metric_score(path_human, path_llm)\n    results.append({\n        \"model\": model_name,\n        \"llm judge\": llm_judge,\n        \"cohen_kappa\": round(kappa, 4),\n        \"spearman_correlation\": round(spearman, 4)\n    })\n\n    print(f\"Aggiunto: model={model_name}, judge={llm_judge}, kappa={round(kappa, 4)}, spearman={round(spearman, 4)}\")\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"metric_score.csv\", index=False, sep=\";\", decimal = \",\")\n\nprint(\"scores saved\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}