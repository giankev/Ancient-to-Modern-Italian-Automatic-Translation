{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#rm -rf /content/*"
      ],
      "metadata": {
        "trusted": true,
        "id": "Sv9VoFTE_k4K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch main https://github.com/giankev/Ancient-to-Modern-Italian-Automatic-Translation.git"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SqwKYKm_k4O",
        "outputId": "4bf67caf-419a-4d76-9933-2d027c562d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Ancient-to-Modern-Italian-Automatic-Translation'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 248 (delta 12), reused 17 (delta 7), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (248/248), 635.16 KiB | 11.14 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "def metric_score(path_human_score, path_LLM_judge_score):\n",
        "\n",
        "    human_score = pd.read_csv(path_human_score)\n",
        "    LLM_judge_score = pd.read_csv(path_LLM_judge_score)\n",
        "\n",
        "    LLM_judge_score = LLM_judge_score[\"score\"]\n",
        "    human_score = human_score[\"human score\"]\n",
        "\n",
        "    kappa = cohen_kappa_score(human_score, LLM_judge_score)\n",
        "    spearman, _ = spearmanr(human_score, LLM_judge_score)\n",
        "\n",
        "    return kappa, spearman"
      ],
      "metadata": {
        "trusted": true,
        "id": "sgerMiqX_k4P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "experiments = [\n",
        "    (\"gemma2b_it_context_learning\",\n",
        "     \"gemini-2.0-flash-lite\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_gemma2b-it_context_learning.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/judge_gemma-2b-it_context_learning/CulturalIA-hw2_transl-judge.csv\"\n",
        "    ),\n",
        "\n",
        "    (\"gemma2b_it_context_learning\",\n",
        "     \"prometheus\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_gemma2b-it_context_learning.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/prometheus/Gemma2b-it-evaluations_prometheus.csv\"\n",
        "    ),\n",
        "\n",
        "    (\"opusMT\",\n",
        "     \"gemini-2.0-flash-lite\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_opusMT.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/judge_opusMT/CulturalIA-hw2_transl-judge.csv\"\n",
        "    ),\n",
        "\n",
        "    (\"opusMT\",\n",
        "     \"prometheus\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_opusMT.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/prometheus/OpusMT-it-evaluations_prometheus.csv\"\n",
        "    ),\n",
        "\n",
        "    (\"minerva350M_finetuned\",\n",
        "     \"gemini-2.0-flash-lite\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_minerva350M_finetuned.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/judge_minerva350M_finetuned/CulturalIA-hw2_transl-judge.csv\"\n",
        "    ),\n",
        "\n",
        "    (\"minerva350M_finetuned\",\n",
        "     \"prometheus\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/human_score/evaluation_human_judge_minerva350M_finetuned.csv\",\n",
        "     \"/content/Ancient-to-Modern-Italian-Automatic-Translation/prometheus/minerva350M_finetuned_evaluations_prometheus.csv\"\n",
        "    )\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name,llm_judge, path_human, path_llm in experiments:\n",
        "    kappa, spearman = metric_score(path_human, path_llm)\n",
        "\n",
        "    if pd.isna(spearman):\n",
        "        spearman = 0\n",
        "\n",
        "    results.append({\n",
        "        \"model\": model_name,\n",
        "        \"llm judge\": llm_judge,\n",
        "        \"cohen_kappa\": round(kappa, 4),\n",
        "        \"spearman_correlation\": round(spearman, 4)\n",
        "    })\n",
        "\n",
        "    print(f\"Aggiunto: model={model_name}, judge={llm_judge}, kappa={round(kappa, 4)}, spearman={round(spearman, 4)}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"metric_score.csv\", index=False, sep=\";\", decimal = \",\")\n",
        "\n",
        "print(\"scores saved\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgNMIfoJ_k4S",
        "outputId": "6ba6fb70-98a1-4a3f-b154-1d8cbc05f075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggiunto: model=gemma2b_it_context_learning, judge=gemini-2.0-flash-lite, kappa=0.0033, spearman=0.2463\n",
            "Aggiunto: model=gemma2b_it_context_learning, judge=prometheus, kappa=-0.047, spearman=0.0406\n",
            "Aggiunto: model=opusMT, judge=gemini-2.0-flash-lite, kappa=0.0427, spearman=0.3939\n",
            "Aggiunto: model=opusMT, judge=prometheus, kappa=0.0985, spearman=0.079\n",
            "Aggiunto: model=minerva350M_finetuned, judge=gemini-2.0-flash-lite, kappa=-0.0356, spearman=-0.0459\n",
            "Aggiunto: model=minerva350M_finetuned, judge=prometheus, kappa=0.0148, spearman=0.1026\n",
            "scores saved\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}